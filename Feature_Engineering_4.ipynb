{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYiy5419FZqV"
      },
      "outputs": [],
      "source": [
        "Q1. What is data encoding? How is it useful in data science?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rR0Sutg_HFo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Encoding in Data Science\n",
        "Data encoding is the process of converting data into a different format, often to prepare it for analysis or to use it with machine learning algorithms. In data science, data encoding is crucial for handling categorical data, which are non-numeric data that represent categories or labels. Machine learning models generally require numerical input, so encoding transforms categorical data into a format that can be provided to these models."
      ],
      "metadata": {
        "id": "OBrowo40FaP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of Data Encoding:\n",
        "Label Encoding:\n",
        "\n",
        "Converts each category to a numerical label.\n",
        "Useful for ordinal data where there is an inherent order.\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "encoded = le.fit_transform(['cat', 'dog', 'mouse'])\n",
        "# Output: array([0, 1, 2])\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HSZ38--1FwGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding:\n",
        "\n",
        "Converts each category into a new binary column (1 or 0).\n",
        "\n",
        "Useful for nominal data where there is no inherent order.\n",
        "\n"
      ],
      "metadata": {
        "id": "4yzNtb1DF-uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "enc = OneHotEncoder()\n",
        "encoded = enc.fit_transform(np.array(['cat', 'dog', 'mouse']).reshape(-1, 1))\n",
        "# Output: sparse matrix which can be converted to array or dataframe\n"
      ],
      "metadata": {
        "id": "hEXRLx8HGLLp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVTv9AfDGL6a",
        "outputId": "54b9339c-155c-44b1-96d8-f315f34601da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Encoding:\n",
        "\n",
        "Converts categories into binary numbers and then splits the digits into separate columns.\n",
        "\n",
        "Useful for high cardinality features."
      ],
      "metadata": {
        "id": "A8qUw1YJGRee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using category_encoders library\n",
        "from category_encoders import BinaryEncoder\n",
        "enc = BinaryEncoder()\n",
        "encoded = enc.fit_transform(['cat', 'dog', 'mouse'])\n"
      ],
      "metadata": {
        "id": "olUsOceWGQgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Encoding:\n",
        "Replaces a categorical value with the mean of the target variable.\n",
        "\n",
        "Useful for high cardinality features when there is a strong relationship between the categorical feature and the target variable."
      ],
      "metadata": {
        "id": "6Ak16yb6Gxn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using category_encoders library\n",
        "from category_encoders import TargetEncoder\n",
        "enc = TargetEncoder()\n",
        "encoded = enc.fit_transform(['cat', 'dog', 'mouse'], target)\n"
      ],
      "metadata": {
        "id": "emFwCoFeGjON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76af3298G5PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importance in Data Science\n",
        "Handling Categorical Data:\n",
        "\n",
        "Most machine learning algorithms require numerical input. Encoding allows categorical data to be used effectively with these algorithms.\n",
        "Improving Model Performance:\n",
        "\n",
        "Proper encoding can lead to better model performance by representing the data more appropriately for the learning algorithm.\n",
        "Feature Engineering:\n",
        "\n",
        "Encoding is a part of feature engineering, which can reveal important patterns and relationships in the data that might not be evident otherwise.\n",
        "Data Preprocessing:\n",
        "\n",
        "It is an essential step in the data preprocessing pipeline, ensuring that all data is in a suitable format for analysis and modeling.\n",
        "By transforming categorical data into numerical form, data encoding facilitates the application of a wide range of machine learning algorithms and helps uncover insights from the data that might otherwise be hidde"
      ],
      "metadata": {
        "id": "EWIWZO9uG_gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario."
      ],
      "metadata": {
        "id": "3ypelm3GHG3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nominal encoding, also known as one-hot encoding, is a process used in data preprocessing to convert categorical variables into a format that can be provided to machine learning algorithms to improve predictions. This technique is particularly useful when dealing with categorical data that does not have any ordinal relationship (i.e., the categories do not have a meaningful order).\n",
        "\n",
        "### How Nominal Encoding Works\n",
        "\n",
        "In nominal encoding, each category value is converted into a new column and assigned a binary value: 1 or 0. If a category is present, it is marked as 1; if not, it is marked as 0. This ensures that the machine learning model does not assume any ordinal relationship between the categories.\n",
        "\n",
        "### Example of Nominal Encoding in a Real-World Scenario\n",
        "\n",
        "Imagine you are working on a dataset that contains information about different types of fruits. One of the columns in your dataset is \"Fruit_Type\" with the following categories:\n",
        "\n",
        "- Apple\n",
        "- Banana\n",
        "- Orange\n",
        "- Grape\n",
        "\n",
        "Before applying machine learning algorithms, you would need to convert these categorical values into a numerical format using nominal encoding. Here’s how you can do it:\n",
        "\n",
        "1. **Original Data:**\n",
        "\n",
        "   | Fruit_Type |\n",
        "   |------------|\n",
        "   | Apple      |\n",
        "   | Banana     |\n",
        "   | Orange     |\n",
        "   | Grape      |\n",
        "   | Apple      |\n",
        "\n",
        "2. **Nominal Encoded Data:**\n",
        "\n",
        "   | Fruit_Type_Apple | Fruit_Type_Banana | Fruit_Type_Orange | Fruit_Type_Grape |\n",
        "   |------------------|-------------------|-------------------|------------------|\n",
        "   | 1                | 0                 | 0                 | 0                |\n",
        "   | 0                | 1                 | 0                 | 0                |\n",
        "   | 0                | 0                 | 1                 | 0                |\n",
        "   | 0                | 0                 | 0                 | 1                |\n",
        "   | 1                | 0                 | 0                 | 0                |\n",
        "\n",
        "### Real-World Scenario: Customer Segmentation\n",
        "\n",
        "Suppose you are working on a customer segmentation project for an e-commerce company. The dataset includes customer information with a \"Preferred_Payment_Method\" column that contains categorical values like:\n",
        "\n",
        "- Credit Card\n",
        "- Debit Card\n",
        "- PayPal\n",
        "- Bank Transfer\n",
        "\n",
        "To use this data for machine learning algorithms, you would apply nominal encoding to the \"Preferred_Payment_Method\" column. The transformed data would look like this:\n",
        "\n",
        "1. **Original Data:**\n",
        "\n",
        "   | Customer_ID | Preferred_Payment_Method |\n",
        "   |-------------|--------------------------|\n",
        "   | 1           | Credit Card              |\n",
        "   | 2           | PayPal                   |\n",
        "   | 3           | Debit Card               |\n",
        "   | 4           | Bank Transfer            |\n",
        "   | 5           | Credit Card              |\n",
        "\n",
        "2. **Nominal Encoded Data:**\n",
        "\n",
        "   | Customer_ID | Payment_Credit_Card | Payment_PayPal | Payment_Debit_Card | Payment_Bank_Transfer |\n",
        "   |-------------|---------------------|----------------|---------------------|-----------------------|\n",
        "   | 1           | 1                   | 0              | 0                   | 0                     |\n",
        "   | 2           | 0                   | 1              | 0                   | 0                     |\n",
        "   | 3           | 0                   | 0              | 1                   | 0                     |\n",
        "   | 4           | 0                   | 0              | 0                   | 1                     |\n",
        "   | 5           | 1                   | 0              | 0                   | 0                     |\n",
        "\n",
        "This encoding allows the machine learning algorithm to process the categorical data effectively without assuming any ordinal relationship between the payment methods."
      ],
      "metadata": {
        "id": "sbmuZ_f4HSdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example."
      ],
      "metadata": {
        "id": "nMXSxsxAIFlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Certainly! Nominal encoding is preferred over one-hot encoding in the following situations:\n",
        "\n",
        "1. **Memory Efficiency**:\n",
        "   - Nominal encoding uses fewer features than one-hot encoding. If memory is a concern, nominal encoding is more efficient.\n",
        "   - Example: In a large dataset with many nominal categories (e.g., product names), one-hot encoding would create an excessive number of binary features. Nominal encoding reduces this overhead.\n",
        "\n",
        "2. **Interpretability**:\n",
        "   - Nominal encoding retains the original category labels, making it easier to interpret model results.\n",
        "   - Example: In a marketing campaign analysis, you want to understand which product categories contribute to sales. Nominal encoding allows you to directly associate model coefficients with product names.\n",
        "\n",
        "3. **Algorithm Compatibility**:\n",
        "   - Some algorithms (e.g., decision trees, Naive Bayes) handle nominal encoding well without requiring one-hot encoding.\n",
        "   - Example: When building a decision tree to predict customer churn, nominal encoding of features like \"payment method\" or \"subscription type\" simplifies the tree structure.\n",
        "\n",
        "Remember, the choice between nominal and one-hot encoding depends on your specific use case, data, and modeling approach. Adapt your encoding strategy accordingly! 🌟🔍"
      ],
      "metadata": {
        "id": "SjTcdvbEIJhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding\n",
        "technique would you use to transform this data into a format suitable for machine learning algorithms?\n",
        "Explain why you made this choice."
      ],
      "metadata": {
        "id": "lHNYgPF4JA7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For nominal data with no inherent order, one-hot encoding is preferred. It ensures that each category is represented independently, avoiding any unintended ranking."
      ],
      "metadata": {
        "id": "FpZYas9pJL92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with a dataset containing categorical data with 5 unique values, the encoding technique you would use largely depends on the nature of the data and the machine learning algorithm you plan to use. Here’s a detailed explanation of why one-hot encoding is typically the preferred choice:\n",
        "\n",
        "### One-Hot Encoding\n",
        "\n",
        "**Reason for Choosing One-Hot Encoding:**\n",
        "- **Simplicity and Compatibility**: One-hot encoding is straightforward to implement and works well with many machine learning algorithms, especially those that do not assume any order among categories.\n",
        "- **Avoids Ordinal Assumptions**: One-hot encoding does not impose any ordinal relationship between the categories, which is suitable for nominal data.\n",
        "- **Limited Number of Unique Values**: With only 5 unique categories, one-hot encoding will create 5 binary columns, which is manageable in terms of dimensionality.\n",
        "\n",
        "### Example and Implementation\n",
        "\n",
        "Suppose you have a dataset with a categorical feature \"Fruit_Type\" containing 5 unique values: Apple, Banana, Orange, Grape, and Mango.\n",
        "\n",
        "1. **Original Data:**\n",
        "\n",
        "   | Fruit_Type |\n",
        "   |------------|\n",
        "   | Apple      |\n",
        "   | Banana     |\n",
        "   | Orange     |\n",
        "   | Grape      |\n",
        "   | Mango      |\n",
        "\n",
        "2. **One-Hot Encoded Data:**\n",
        "\n",
        "   | Fruit_Type_Apple | Fruit_Type_Banana | Fruit_Type_Orange | Fruit_Type_Grape | Fruit_Type_Mango |\n",
        "   |------------------|-------------------|-------------------|------------------|------------------|\n",
        "   | 1                | 0                 | 0                 | 0                | 0                |\n",
        "   | 0                | 1                 | 0                 | 0                | 0                |\n",
        "   | 0                | 0                 | 1                 | 0                | 0                |\n",
        "   | 0                | 0                 | 0                 | 1                | 0                |\n",
        "   | 0                | 0                 | 0                 | 0                | 1                |\n",
        "\n",
        "### Other Considerations\n",
        "\n",
        "While one-hot encoding is generally the best choice for a small number of unique categories, here are a few other encoding techniques and why they might not be as suitable in this case:\n",
        "\n",
        "1. **Label Encoding**:\n",
        "   - **Reason Against**: Label encoding assigns an integer value to each category, which can introduce unintended ordinal relationships. For example, Apple = 0, Banana = 1, etc. This can mislead algorithms into thinking there is a ranking order.\n",
        "\n",
        "2. **Binary Encoding**:\n",
        "   - **Reason Against**: Binary encoding is more complex and is typically used for high cardinality categorical variables. It converts categories into binary digits, reducing dimensionality but is unnecessary for just 5 categories.\n",
        "\n",
        "3. **Target Encoding**:\n",
        "   - **Reason Against**: Target encoding involves replacing categories with a statistical measure (like mean target value), which can introduce data leakage if not handled properly. It is more suitable for high cardinality data.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "For a categorical feature with 5 unique values, one-hot encoding is the most appropriate technique because it effectively handles nominal data without imposing any ordinal structure, and the resultant dimensionality is still manageable for most machine learning algorithms."
      ],
      "metadata": {
        "id": "Bbjp_Sq7Jtdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
        "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
        "transform the categorical data, how many new columns would be created? Show your calculations."
      ],
      "metadata": {
        "id": "nrovimpnJyUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! When using nominal encoding, we convert categorical data into integer format. For this purpose, we typically employ one-hot encoding. Here's how it works:\n",
        "\n",
        "1. **Nominal Data**: Nominal data represents categories without any intrinsic order. Examples include gender, color, or letters. Since nominal data lacks a natural order, we use one-hot encoding.\n",
        "\n",
        "2. **One-Hot Encoding**: In one-hot encoding, each category becomes a binary column. For a nominal variable with *k* categories, we create *k* new columns. Each row has a 1 in the corresponding category column and 0s in the other columns.\n",
        "\n",
        "   - Given that you have 2 categorical columns, you'll create 2 sets of new columns.\n",
        "   - For each set, the number of new columns equals the number of unique categories in that column.\n",
        "\n",
        "3. **Calculations**:\n",
        "   - Let's assume the first categorical column has *m* unique categories, and the second categorical column has *n* unique categories.\n",
        "   - Total new columns = *m* (from the first column) + *n* (from the second column).\n",
        "\n",
        "   If you provide the specific number of unique categories for each column, I can give you the exact count of new columns! 😊\n",
        "\n"
      ],
      "metadata": {
        "id": "DJxP9fT_J4k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. You are working with a dataset containing information about different types of animals, including their\n",
        "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
        "a format suitable for machine learning algorithms? Justify your answer"
      ],
      "metadata": {
        "id": "8sof17PqKJVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform categorical data into a format suitable for machine learning algorithms, the choice of encoding technique depends on the nature of the categorical data and the specific machine learning algorithm being used. Here are some common encoding techniques and when to use them:\n",
        "\n",
        "1. **One-Hot Encoding**:\n",
        "    - **When to use**: This is suitable when the categorical variables are nominal (i.e., categories do not have an inherent order). Examples include species, habitat, and diet when they are simply categories without any ordinal relationship.\n",
        "    - **Why**: One-hot encoding creates a new binary column for each unique category, allowing algorithms that rely on numerical input to use the data effectively without assuming any order among the categories.\n",
        "    \n",
        "2. **Label Encoding**:\n",
        "    - **When to use**: This is suitable for ordinal categorical variables (i.e., categories have a meaningful order). Examples might include categories like \"small\", \"medium\", and \"large\" if these sizes are ordered.\n",
        "    - **Why**: Label encoding assigns each category a unique integer, preserving the ordinal relationship. However, it can introduce unintended ordinal relationships if used with nominal data.\n",
        "\n",
        "3. **Target Encoding (Mean Encoding)**:\n",
        "    - **When to use**: This can be useful in certain cases where you have high cardinality in categorical data and want to avoid creating too many dummy variables. It’s often used in tree-based algorithms.\n",
        "    - **Why**: Target encoding replaces the category with the mean of the target variable for that category, capturing the relationship between the category and the target.\n",
        "\n",
        "### Recommended Approach for the Given Dataset\n",
        "\n",
        "For a dataset containing information about different types of animals, including their species, habitat, and diet, one-hot encoding is typically the best choice. Here’s why:\n",
        "\n",
        "- **Species**: This is a nominal variable as there is no inherent order among different species of animals. One-hot encoding would create binary columns for each species, effectively handling this type of categorical data.\n",
        "- **Habitat**: Assuming habitat categories such as forest, desert, ocean, etc., are also nominal without any inherent order. One-hot encoding is appropriate here as well.\n",
        "- **Diet**: Assuming diet categories such as herbivore, carnivore, omnivore, etc., are nominal, one-hot encoding would be suitable. If there’s an ordinal relationship (e.g., primary carnivore, secondary carnivore), label encoding might be considered, but this is less common.\n",
        "\n",
        "### Example Justification\n",
        "\n",
        "Let’s break down why one-hot encoding is the preferred technique:\n",
        "\n",
        "- **Avoids Ordinal Misinterpretation**: One-hot encoding ensures that the model does not assume any ordinal relationship among categories. For instance, treating \"forest\", \"desert\", and \"ocean\" habitats as 1, 2, and 3, respectively, could mislead the model into thinking \"ocean\" > \"desert\" > \"forest\", which is incorrect.\n",
        "- **Compatibility with Most Algorithms**: Many machine learning algorithms, such as logistic regression, support vector machines, and neural networks, perform better when categorical variables are one-hot encoded because it allows the algorithm to treat each category independently.\n",
        "- **Prevents Information Loss**: Unlike label encoding, which might combine categories into a single numerical feature, one-hot encoding preserves the distinctness of each category, ensuring no information is lost.\n",
        "\n",
        "In summary, for the dataset with animal information including species, habitat, and diet, one-hot encoding is the most suitable technique because it handles nominal categories effectively, prevents ordinal misinterpretation, and is compatible with a wide range of machine learning algorithms."
      ],
      "metadata": {
        "id": "vC1PBHS9LRSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
        "company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
        "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
        "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding."
      ],
      "metadata": {
        "id": "4NlBc4R6LXMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict customer churn using a dataset with categorical and numerical features, you need to encode the categorical features into a numerical format that can be used by machine learning algorithms. Here’s a step-by-step explanation of how you would implement the encoding:\n",
        "\n",
        "### Step 1: Identify Categorical Features\n",
        "In your dataset, identify which features are categorical. From your description, it seems that \"gender\" and \"contract type\" are categorical features, while \"age,\" \"monthly charges,\" and \"tenure\" are numerical.\n",
        "\n",
        "### Step 2: Choose Encoding Techniques\n",
        "The two common encoding techniques for categorical data are:\n",
        "\n",
        "1. **Label Encoding**: Assigns a unique integer to each category.\n",
        "2. **One-Hot Encoding**: Creates a new binary column for each category of the feature.\n",
        "\n",
        "### Step 3: Implement Label Encoding for Binary Categories\n",
        "For features with two categories (binary), label encoding is straightforward and effective.\n",
        "\n",
        "**Example: Gender**\n",
        "- Male -> 0\n",
        "- Female -> 1\n",
        "\n",
        "### Step 4: Implement One-Hot Encoding for Multi-Category Features\n",
        "For features with more than two categories, one-hot encoding is generally preferred to avoid implying an ordinal relationship between the categories.\n",
        "\n",
        "**Example: Contract Type**\n",
        "- Month-to-month\n",
        "- One year\n",
        "- Two year\n",
        "\n",
        "One-hot encoding will transform \"Contract Type\" into three binary columns:\n",
        "- Contract Type_Month-to-month\n",
        "- Contract Type_One year\n",
        "- Contract Type_Two year\n",
        "\n",
        "### Step 5: Use Libraries to Implement Encoding\n",
        "You can use libraries like `pandas` and `scikit-learn` to implement these encodings.\n",
        "\n",
        "#### Example Code\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'gender': ['Male', 'Female', 'Female', 'Male'],\n",
        "    'age': [24, 45, 34, 23],\n",
        "    'contract_type': ['Month-to-month', 'One year', 'Two year', 'Month-to-month'],\n",
        "    'monthly_charges': [29.85, 56.95, 42.30, 89.10],\n",
        "    'tenure': [1, 23, 12, 5]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Label Encoding for 'gender'\n",
        "label_encoder = LabelEncoder()\n",
        "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
        "\n",
        "# One-Hot Encoding for 'contract_type'\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "contract_type_encoded = one_hot_encoder.fit_transform(df[['contract_type']]).toarray()\n",
        "\n",
        "# Create a DataFrame from the one-hot encoded array\n",
        "contract_type_df = pd.DataFrame(contract_type_encoded, columns=one_hot_encoder.get_feature_names_out(['contract_type']))\n",
        "\n",
        "# Concatenate the original DataFrame (without 'contract_type') and the new one-hot encoded DataFrame\n",
        "df = pd.concat([df.drop('contract_type', axis=1), contract_type_df], axis=1)\n",
        "\n",
        "print(df)\n",
        "```\n",
        "\n",
        "### Step 6: Verify Encoded Data\n",
        "Ensure the encoded data is correctly transformed and integrated into the dataset. The final DataFrame should contain numerical values for both originally numerical and now encoded categorical features.\n",
        "\n",
        "### Step 7: Use the Encoded Data for Machine Learning\n",
        "Now, your dataset is ready to be used for training machine learning models to predict customer churn.\n",
        "\n",
        "This process ensures that categorical data is appropriately transformed into numerical data, allowing machine learning algorithms to effectively use all features in the dataset."
      ],
      "metadata": {
        "id": "KYo9mg2TLcc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'gender': ['Male', 'Female', 'Female', 'Male'],\n",
        "    'age': [24, 45, 34, 23],\n",
        "    'contract_type': ['Month-to-month', 'One year', 'Two year', 'Month-to-month'],\n",
        "    'monthly_charges': [29.85, 56.95, 42.30, 89.10],\n",
        "    'tenure': [1, 23, 12, 5]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Label Encoding for 'gender'\n",
        "label_encoder = LabelEncoder()\n",
        "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
        "\n",
        "# One-Hot Encoding for 'contract_type'\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "contract_type_encoded = one_hot_encoder.fit_transform(df[['contract_type']]).toarray()\n",
        "\n",
        "# Create a DataFrame from the one-hot encoded array\n",
        "contract_type_df = pd.DataFrame(contract_type_encoded, columns=one_hot_encoder.get_feature_names_out(['contract_type']))\n",
        "\n",
        "# Concatenate the original DataFrame (without 'contract_type') and the new one-hot encoded DataFrame\n",
        "df = pd.concat([df.drop('contract_type', axis=1), contract_type_df], axis=1)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aOR4dbzMALb",
        "outputId": "e5e8ea4c-a44a-46a4-bdb8-c5b8ea3d578b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gender  age  monthly_charges  tenure  contract_type_Month-to-month  \\\n",
            "0       1   24            29.85       1                           1.0   \n",
            "1       0   45            56.95      23                           0.0   \n",
            "2       0   34            42.30      12                           0.0   \n",
            "3       1   23            89.10       5                           1.0   \n",
            "\n",
            "   contract_type_One year  contract_type_Two year  \n",
            "0                     0.0                     0.0  \n",
            "1                     1.0                     0.0  \n",
            "2                     0.0                     1.0  \n",
            "3                     0.0                     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpTXUmukMA6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}