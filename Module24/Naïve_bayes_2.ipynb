{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
        "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
        "probability that an employee is a smoker given that he/she uses the health insurance plan?"
      ],
      "metadata": {
        "id": "0U7F9ClJBdc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A: the employee uses the health insurance plan\n",
        "\n",
        "B: the employee is a smoker\n",
        "We are given the following probabilities:\n",
        "\n",
        "P(A) = 0.7 (70% of the employees use the company's health insurance plan) P(B|A) = 0.4 (40% of the employees who use the plan are smokers)\n",
        "\n",
        "We want to find P(B|A), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
        "\n",
        "Using Bayes' theorem, we have:\n",
        "\n",
        "P(B|A) = P(A|B) * P(B) / P(A)\n",
        "\n",
        "We can find each of these probabilities as follows:\n",
        "\n",
        "P(B) = the overall probability of being a smoker, which we are not given directly. However, we can find it using the law of total probability:\n",
        "\n",
        "P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\n",
        "\n",
        "We are given P(B|A) = 0.4 and P(A) = 0.7, and we can assume that P(B|not A) is the proportion of employees who are smokers but do not use the health insurance plan. We are not given this proportion, but we can assume it is smaller than 40%, since the use of health insurance plan is likely to be higher among smokers.\n",
        "\n",
        "Let's assume P(B|not A) = 0.2, which means that 20% of the employees who do not use the plan are smokers. Then:\n",
        "\n",
        "P(B) = 0.4 * 0.7 + 0.2 * 0.3 = 0.34\n",
        "\n",
        "Next, we need to find P(A|B), the probability that an employee uses the health insurance plan given that he/she is a smoker. We can assume that this proportion is higher than the overall proportion of 70%, since smokers are more likely to use health insurance. Let's assume P(A|B) = 0.8, which means that 80% of smokers use the plan. Then:\n",
        "\n",
        "P(B|A) = 0.4 P(A) = 0.7 P(B) = 0.34 P(A|B) = P(B|A) * P(A) / P(B) = 0.4 * 0.7 / 0.34 = 0.82\n",
        "\n",
        "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.82."
      ],
      "metadata": {
        "id": "mSLZPSY3JCJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
      ],
      "metadata": {
        "id": "uPsTVzyUJLoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variations of the Naive Bayes classifier, but they handle features and data distributions differently:\n",
        "\n",
        "### Bernoulli Naive Bayes\n",
        "- **Feature Assumption**: Assumes binary/Boolean features. Each feature is either present or absent.\n",
        "- **Data Distribution**: Models the features as following a Bernoulli distribution (i.e., each feature is either 0 or 1).\n",
        "- **Use Case**: Best suited for text classification tasks where the presence or absence of a word (or other features) is of interest, rather than the frequency of occurrences.\n",
        "- **Example**: Given a text document, features could be the presence or absence of certain words.\n",
        "\n",
        "### Multinomial Naive Bayes\n",
        "- **Feature Assumption**: Assumes features are counts or frequencies of occurrences.\n",
        "- **Data Distribution**: Models the features as following a multinomial distribution, which is suitable for count data or frequencies.\n",
        "- **Use Case**: Ideal for text classification tasks where the frequency of terms or words is important. It works well when you have word counts or term frequencies as features.\n",
        "- **Example**: Given a text document, features could be the number of times each word appears.\n",
        "\n",
        "### Summary\n",
        "- **Bernoulli Naive Bayes**: Assumes binary features (presence/absence).\n",
        "- **Multinomial Naive Bayes**: Assumes features are counts or frequencies.\n",
        "\n",
        "In practice, you would choose between them based on whether your features are binary or represent counts/frequencies."
      ],
      "metadata": {
        "id": "z5c3foSiJPFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does Bernoulli Naive Bayes handle missing values?"
      ],
      "metadata": {
        "id": "C9diWAlOTKMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with missing values in a Bernoulli Naive Bayes model, there are a few considerations:\n",
        "\n",
        "1. **Omitting Missing Values**: The scikit-learn implementation of Bernoulli Naive Bayes omits missing values while constructing probability tables¹. This means that when calculating probabilities, the algorithm ignores categories with missing values. Essentially, it only computes probabilities based on the specific categories provided with non-missing values.\n",
        "\n",
        "2. **Handling Missing Data**: If your dataset contains NaN values (missing data), you don't need to explicitly replace them with placeholders like -1 or impute average values. Instead, the algorithm automatically excludes these missing values during probability calculations.\n",
        "\n",
        "3. **Categorical Data**: Since Bernoulli Naive Bayes is designed for binary/boolean features, it's appropriate for your categorical data where each attribute is either seen (1) or not seen (0). If an attribute value is missing (NaN), it won't contribute to the probability calculation for that specific category.\n",
        "\n",
        "In summary, the best approach is to let the algorithm handle missing values by ignoring them during probability estimation. You've already removed data points where content_1 is NaN, focusing on cases where active decisions were made by users¹. This ensures that missing values do not affect the probability calculations for your specific use case.\n"
      ],
      "metadata": {
        "id": "Clizuk8bUE2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
      ],
      "metadata": {
        "id": "rM1pW9xLTPT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Gaussian Naive Bayes (GaussianNB) is indeed suitable for multi-class classification tasks. Let me explain how it works.\n",
        "\n",
        "Gaussian Naive Bayes is a probabilistic classification technique that assumes each class follows a normal distribution. It makes the \"naive\" assumption that each feature is conditionally independent given the class label. Here are the key points:\n",
        "\n",
        "1. **Assumption of Normal Distribution**: GaussianNB assumes that the features within each class follow a Gaussian (normal) distribution. This means that the likelihood of observing a particular feature value given the class label follows a bell-shaped curve.\n",
        "\n",
        "2. **Independence Assumption**: The \"naive\" part of Naive Bayes comes from assuming that the features are independent of each other, given the class label. While this assumption rarely holds in practice, GaussianNB can still perform well if the features are approximately independent.\n",
        "\n",
        "3. **Multi-Class Classification**: GaussianNB can handle multi-class classification problems. It assigns a class label to an input based on the maximum posterior probability (computed using Bayes' theorem) across all classes.\n",
        "\n",
        "4. **Online Updates**: GaussianNB can perform online updates to model parameters via `partial_fit`. This means you can update the model incrementally as new data arrives.\n",
        "\n",
        "Here's a simple example using Python and scikit-learn:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Example data\n",
        "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
        "Y = np.array([1, 1, 1, 2, 2, 2])\n",
        "\n",
        "# Create and fit the GaussianNB model\n",
        "clf = GaussianNB()\n",
        "clf.fit(X, Y)\n",
        "\n",
        "# Predict a new data point\n",
        "new_data_point = np.array([[-0.8, -1]])\n",
        "predicted_class = clf.predict(new_data_point)\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "```\n",
        "\n",
        "Remember that GaussianNB assumes continuous features following a normal distribution. If your data violates this assumption significantly, consider other Naive Bayes variants like MultinomialNB (for discrete features) or BernoulliNB (for binary features) ¹.\n",
        "\n"
      ],
      "metadata": {
        "id": "QNEmjhhDVoOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a Python program using the GaussianNB class from the sklearn library to demonstrate multi-class classification. In this example, we'll use the Iris dataset, which is a classic dataset for classification problems with three classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvgU9taSe4qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "tGZp79dWfIBR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n"
      ],
      "metadata": {
        "id": "EHgadvZ1fICV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "x8CprpSzfToG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "gnb = GaussianNB()\n"
      ],
      "metadata": {
        "id": "oELnit-jfW6G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on the training data\n",
        "gnb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "60DCEqQZfZlG",
        "outputId": "9bda9a7f-1e7d-4b2a-f0bd-3af081d9ba56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the classes on the test data\n",
        "y_pred = gnb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "V5aMuuaafdSl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy and print the classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaF7LPPsfhgm",
        "outputId": "b63d4ad8-c85f-4af4-8271-af2e409610b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_NCEheYfmZ2",
        "outputId": "df1b830d-19a0-4e05-ba38-266f817e1a3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      0.92      0.96        13\n",
            "   virginica       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Assignment:\n",
        "\n",
        "## Data preparation:\n",
        "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
        "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
        "is spam or not based on several input features.\n",
        "\n",
        "## Implementation:\n",
        "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
        "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
        "dataset. You should use the default hyperparameters for each classifier.\n",
        "\n",
        "## Results:\n",
        "Report the following performance metrics for each classifier:\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1 score\n",
        "\n",
        "\n",
        "## Discussion:\n",
        "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
        "the case? Are there any limitations of Naive Bayes that you observed?\n",
        "\n",
        "## Conclusion:\n",
        "Summarise your findings and provide some suggestions for future work."
      ],
      "metadata": {
        "id": "rJc5USFyftqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation:\n",
        "First, download the Spambase Data Set from the UCI Machine Learning Repository. You can download the dataset file (spambase.data) and load it into a pandas DataFrame."
      ],
      "metadata": {
        "id": "R1n4hlNbiGqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Implementing Naive Bayes Classifiers\n",
        "You need to implement three types of Naive Bayes classifiers using scikit-learn:\n",
        "* Bernoulli Naive Bayes\n",
        "* Multinomial Naive Bayes\n",
        "* Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "b9QplYqptnWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "NUBJuStduNxZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "columns = [f'feature_{i}' for i in range(1, 58)] + ['label']\n",
        "data = pd.read_csv(url, header=None, names=columns)\n"
      ],
      "metadata": {
        "id": "465bscmvugRU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XJlGBQekurpE",
        "outputId": "7ce994f8-82a2-4605-c99b-40c58d9a68c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0          0.00       0.64       0.64        0.0       0.32       0.00   \n",
              "1          0.21       0.28       0.50        0.0       0.14       0.28   \n",
              "2          0.06       0.00       0.71        0.0       1.23       0.19   \n",
              "3          0.00       0.00       0.00        0.0       0.63       0.00   \n",
              "4          0.00       0.00       0.00        0.0       0.63       0.00   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "4596       0.31       0.00       0.62        0.0       0.00       0.31   \n",
              "4597       0.00       0.00       0.00        0.0       0.00       0.00   \n",
              "4598       0.30       0.00       0.30        0.0       0.00       0.00   \n",
              "4599       0.96       0.00       0.00        0.0       0.32       0.00   \n",
              "4600       0.00       0.00       0.65        0.0       0.00       0.00   \n",
              "\n",
              "      feature_7  feature_8  feature_9  feature_10  ...  feature_49  \\\n",
              "0          0.00       0.00       0.00        0.00  ...       0.000   \n",
              "1          0.21       0.07       0.00        0.94  ...       0.000   \n",
              "2          0.19       0.12       0.64        0.25  ...       0.010   \n",
              "3          0.31       0.63       0.31        0.63  ...       0.000   \n",
              "4          0.31       0.63       0.31        0.63  ...       0.000   \n",
              "...         ...        ...        ...         ...  ...         ...   \n",
              "4596       0.00       0.00       0.00        0.00  ...       0.000   \n",
              "4597       0.00       0.00       0.00        0.00  ...       0.000   \n",
              "4598       0.00       0.00       0.00        0.00  ...       0.102   \n",
              "4599       0.00       0.00       0.00        0.00  ...       0.000   \n",
              "4600       0.00       0.00       0.00        0.00  ...       0.000   \n",
              "\n",
              "      feature_50  feature_51  feature_52  feature_53  feature_54  feature_55  \\\n",
              "0          0.000         0.0       0.778       0.000       0.000       3.756   \n",
              "1          0.132         0.0       0.372       0.180       0.048       5.114   \n",
              "2          0.143         0.0       0.276       0.184       0.010       9.821   \n",
              "3          0.137         0.0       0.137       0.000       0.000       3.537   \n",
              "4          0.135         0.0       0.135       0.000       0.000       3.537   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "4596       0.232         0.0       0.000       0.000       0.000       1.142   \n",
              "4597       0.000         0.0       0.353       0.000       0.000       1.555   \n",
              "4598       0.718         0.0       0.000       0.000       0.000       1.404   \n",
              "4599       0.057         0.0       0.000       0.000       0.000       1.147   \n",
              "4600       0.000         0.0       0.125       0.000       0.000       1.250   \n",
              "\n",
              "      feature_56  feature_57  label  \n",
              "0             61         278      1  \n",
              "1            101        1028      1  \n",
              "2            485        2259      1  \n",
              "3             40         191      1  \n",
              "4             40         191      1  \n",
              "...          ...         ...    ...  \n",
              "4596           3          88      0  \n",
              "4597           4          14      0  \n",
              "4598           6         118      0  \n",
              "4599           5          78      0  \n",
              "4600           5          40      0  \n",
              "\n",
              "[4601 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6977cb9-148e-423d-9105-2a39774c2a53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4601 rows × 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6977cb9-148e-423d-9105-2a39774c2a53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6977cb9-148e-423d-9105-2a39774c2a53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6977cb9-148e-423d-9105-2a39774c2a53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6f43153-acf0-43fb-87ca-db498c7eed9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6f43153-acf0-43fb-87ca-db498c7eed9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6f43153-acf0-43fb-87ca-db498c7eed9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_54906583-1c68-4256-9657-fccb5651d8c5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_54906583-1c68-4256-9657-fccb5651d8c5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the features and target\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['label']\n"
      ],
      "metadata": {
        "id": "9KcWYMjfut90"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "coo15Ot5u1QE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifiers\n",
        "bernoulli_nb = BernoulliNB()\n",
        "multinomial_nb = MultinomialNB()\n",
        "gaussian_nb = GaussianNB()\n",
        "\n"
      ],
      "metadata": {
        "id": "vdyBzbAku4jU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate classifier\n",
        "def evaluate_classifier(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "ifVU_vOxu_QF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Bernoulli Naive Bayes\n",
        "accuracy, precision, recall, f1 = evaluate_classifier(bernoulli_nb, X_train, X_test, y_train, y_test)\n",
        "print(\"Bernoulli Naive Bayes:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUhOJS93vCs0",
        "outputId": "7ba567a9-ce70-47de-b82d-7c4707ad4970"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes:\n",
            "Accuracy: 0.8791\n",
            "Precision: 0.8883\n",
            "Recall: 0.8128\n",
            "F1 Score: 0.8489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Multinomial Naive Bayes\n",
        "accuracy, precision, recall, f1 = evaluate_classifier(multinomial_nb, X_train, X_test, y_train, y_test)\n",
        "print(\"\\nMultinomial Naive Bayes:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZIRo1okvGGk",
        "outputId": "aeb388c9-426a-472d-9651-f63d2c9cf5d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multinomial Naive Bayes:\n",
            "Accuracy: 0.7820\n",
            "Precision: 0.7624\n",
            "Recall: 0.6950\n",
            "F1 Score: 0.7271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Gaussian Naive Bayes\n",
        "accuracy, precision, recall, f1 = evaluate_classifier(gaussian_nb, X_train, X_test, y_train, y_test)\n",
        "print(\"\\nGaussian Naive Bayes:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94l1xamLvMc0",
        "outputId": "d93e77ca-aac5-4cff-9e48-0275f29ba8b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gaussian Naive Bayes:\n",
            "Accuracy: 0.8248\n",
            "Precision: 0.7207\n",
            "Recall: 0.9480\n",
            "F1 Score: 0.8189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Discussion\n",
        "## Results Analysis:\n",
        "1. Performance Comparison: Compare the accuracy, precision, recall, and F1 score of each classifier. This will show which model performed best overall and in terms of each metric.\n",
        "\n",
        "2. Why the Best Model Performed Better:\n",
        "* Bernoulli Naive Bayes: Assumes binary features (0 or 1). It might perform well if the dataset's features are binary or sparse.\n",
        "* Multinomial Naive Bayes: Works well with count data and is typically used for text classification where feature vectors are word count\n",
        "* Gaussian Naive Bayes: Assumes features are normally distributed, which might not be suitable if the features don't follow this distribution.\n",
        "\n",
        "3. Limitations of Naive Bayes:\n",
        "\n",
        "  * Assumes feature independence, which might not always be true.\n",
        "  * May not perform well if the features are not distributed according to the assumptions of the model (e.g., Gaussian distribution for Gaussian Naive Bayes)."
      ],
      "metadata": {
        "id": "LLnS00MivV0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Conclusion\n",
        "Summarize the performance of each classifier and provide insights into why certain models may have performed better. Suggest possible future work, such as trying different feature engineering techniques, tuning hyperparameters, or using more advanced classifiers."
      ],
      "metadata": {
        "id": "3hLfL2hNwKAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M4NudyxGwV60"
      }
    }
  ]
}